trial,alg,reward_fn,hyper_params
0,DDQN,"{'hungry and thirsty': -1.0, 'hungry and not thirsty': -0.7, 'not hungry and thirsty': -0.5, 'not hungry and not thirsty': 1.0}","{'gamma': 0.9, 'num_episodes': 2500, 'lr': 0.001, 'update_steps': 64, 'batch_size': 64, 'epsilon_min': 0.1, 'epsilon_decay': 50000, 'reward_scaling_factor': 1}"
1,DDQN,"{'hungry and thirsty': -1.0, 'hungry and not thirsty': -0.7, 'not hungry and thirsty': -0.2, 'not hungry and not thirsty': 1.0}","{'gamma': 0.99, 'num_episodes': 5000, 'lr': 0.0001, 'update_steps': 1, 'batch_size': 64, 'epsilon_min': 0.1, 'epsilon_decay': 50000, 'reward_scaling_factor': 1}"
2,DDQN,"{'hungry and thirsty': -1.0, 'hungry and not thirsty': -0.7, 'not hungry and thirsty': -0.2, 'not hungry and not thirsty': 1.0}","{'gamma': 0.99, 'num_episodes': 5000, 'lr': 0.001, 'update_steps': 1, 'batch_size': 64, 'epsilon_min': 0.1, 'epsilon_decay': 50000, 'reward_scaling_factor': 1}"
3,DDQN,"{'hungry and thirsty': -1.0, 'hungry and not thirsty': -0.7, 'not hungry and thirsty': -0.2, 'not hungry and not thirsty': 1.0}","{'gamma': 0.99, 'num_episodes': 5000, 'lr': 0.001, 'update_steps': 64, 'batch_size': 64, 'epsilon_min': 0.1, 'epsilon_decay': 50000, 'reward_scaling_factor': 1}"
4,PPO,"{'hungry and thirsty': -1.0, 'hungry and not thirsty': -0.7, 'not hungry and thirsty': -0.2, 'not hungry and not thirsty': 1.0}","{'gamma': 0.99, 'num_episodes': 2500, 'lr': 0.0001, 'update_steps': 64, 'eps_clip': 0.1, 'entropy_coeff': 0.01, 'reward_scaling_factor': 1}"

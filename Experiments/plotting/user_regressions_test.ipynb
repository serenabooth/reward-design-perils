{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import heapq\n",
    "import csv\n",
    "import sys\n",
    "from copy import copy\n",
    "import os \n",
    "module_path = os.path.abspath(os.path.join('../../RL_algorithms'))\n",
    "sys.path.insert(0, module_path)\n",
    "from Utils import tsplot, find_filenames_with_extension\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import kendalltau\n",
    "import matplotlib.patches as mpatches\n",
    "import itertools\n",
    "import heapq\n",
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"../../User_Studies/Expert-User-Study/user_tests/\"\n",
    "BASE = \"../saved_reward_fn_performances/AAAI_Experiments/\"\n",
    "\n",
    "last_user_id = None\n",
    "users = range(0,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/serena/AAAI_23_reward_design/Experiments/plotting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 107/107 [00:18<00:00,  5.67it/s]\n",
      "100%|████████████████████████████████████████| 107/107 [00:18<00:00,  5.76it/s]\n",
      "100%|████████████████████████████████████████| 107/107 [00:19<00:00,  5.57it/s]\n",
      "100%|████████████████████████████████████████| 107/107 [00:19<00:00,  5.45it/s]\n"
     ]
    }
   ],
   "source": [
    "DEEP_LOCS = [\"UserRewardFnReRunWithDefaultParams/PPO\",\n",
    "             \"UserRewardFnReRunWithDefaultParams/A2C\",\n",
    "             \"UserRewardFnReRunWithDefaultParams/DDQN\",\n",
    "             \"UserRewardFnReRunWithDefaultParams/Q_Learn\"]\n",
    "DIRS_LOCS = DEEP_LOCS\n",
    "\n",
    "DIR_LABELS = {\"QLearnAlpha0pt25\": \"Alpha=0.25\",\n",
    "              \"QLearnBaseline\": \"Baseline\",\n",
    "              \"QLearnGamma0pt8\": \"Gamma=0.8\",\n",
    "              \"QLearnGamma0pt5\": \"Gamma=0.5\",\n",
    "              \"UserRewardFnReRunWithDefaultParams/PPO\": \"PPO\",\n",
    "              \"UserRewardFnReRunWithDefaultParams/A2C\": \"A2C\",\n",
    "              \"UserRewardFnReRunWithDefaultParams/DDQN\": \"DDQN\",\n",
    "              \"UserRewardFnReRunWithDefaultParams/Q_Learn\": \"QLearn\"\n",
    "              }\n",
    "\n",
    "def read_csv_into_heapq(h, csv_filename, line_limit=10):\n",
    "    \"\"\"\n",
    "    Read csv into a heapq\n",
    "\n",
    "    heapq documentation: https://docs.python.org/3/library/heapq.html\n",
    "    :param heapq: h\n",
    "    :param csv_filename: string\n",
    "    :param line_limit: int, the number of trials to read in \n",
    "    :return: heapq\n",
    "    \"\"\"\n",
    "    csv_file = open(csv_filename, \"r\")\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    hyper_params = next(csv_reader)  # gets the first line (which just records hyperparams)\n",
    "    reward_fn = next(csv_reader) # gets the second line (which just records the reward fn)\n",
    "    performance = []\n",
    "    for idx, row in enumerate(csv_reader):\n",
    "        if idx >= line_limit:\n",
    "            continue\n",
    "        running_total = 0\n",
    "        row = [[running_total := running_total + eval(x)[0]-1] for x in row]  # subtract 1 since every ep starts -H\n",
    "        performance.append(row)\n",
    "\n",
    "    data = np.array(performance)\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.concatenate(data, axis=-1)\n",
    "        data = np.mean(data, axis=-1)\n",
    "        \n",
    "    reward_fn = [eval(elem)[1] for elem in reward_fn]\n",
    "    heapq.heappush(h, (data[-1], str(reward_fn)))\n",
    "    \n",
    "li = []\n",
    "\n",
    "DIRS = []\n",
    "import os\n",
    "print (os.getcwd())\n",
    "\n",
    "for dir in DIRS_LOCS:\n",
    "    h = []\n",
    "\n",
    "    csv_files = find_filenames_with_extension(BASE + dir, \"csv\")\n",
    "    for file in tqdm(csv_files):\n",
    "        read_csv_into_heapq(h, BASE + dir + \"/\" + file)\n",
    "    DIRS.append(DIR_LABELS[dir])\n",
    "    df = pd.DataFrame(h, columns=[DIR_LABELS[dir], 'Reward Function'])\n",
    "    li.append(df)\n",
    "    del h\n",
    "    \n",
    "\n",
    "cumulative_df = li[0]\n",
    "join_cols = [\"Reward Function\"]\n",
    "color_cm = plt.get_cmap(\"viridis\")\n",
    "\n",
    "for i in range(1, len(DIRS)):\n",
    "    cumulative_df = cumulative_df.merge(li[i], on=join_cols)\n",
    "cumulative_df['PPO_rank'] = cumulative_df['PPO'].rank(ascending=False)\n",
    "cumulative_df['QLearn_rank'] = cumulative_df['QLearn'].rank(ascending=False)\n",
    "cumulative_df['DDQN_rank'] = cumulative_df['DDQN'].rank(ascending=False)\n",
    "cumulative_df['A2C_rank'] = cumulative_df['A2C'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User  0\n",
      "User  1\n",
      "User  2\n",
      "User  3\n",
      "User  4\n",
      "User  5\n",
      "User  6\n",
      "User  7\n",
      "User  8\n",
      "User  9\n",
      "User  10\n",
      "User  11\n",
      "User  12\n",
      "User  13\n",
      "User  14\n",
      "User  15\n",
      "User  16\n",
      "User  17\n",
      "User  18\n",
      "User  19\n",
      "User  20\n",
      "User  21\n",
      "User  22\n",
      "User  23\n",
      "User  24\n",
      "User  25\n",
      "User  26\n",
      "User  27\n",
      "User  28\n",
      "User  29\n"
     ]
    }
   ],
   "source": [
    "with open(BASE_DIR + \"/user_overfitting.csv\", 'w', newline=\"\") as overfitting_save_csv:\n",
    "    overfitting_csv_writer = csv.writer(overfitting_save_csv, delimiter=',',\n",
    "                        quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    overfitting_csv_writer.writerow(['User', \n",
    "                                     'Reward Fn', \n",
    "                                     'Valid?', \n",
    "                                     'Selected?', \n",
    "                                     'DDQN Rank', \n",
    "                                     'DDQN Mean', \n",
    "                                     'PPO Rank', \n",
    "                                     'PPO Mean', \n",
    "                                     'A2C Rank', \n",
    "                                     'A2C Mean', \n",
    "                                     'QLearn Rank', \n",
    "                                     'QLearn Mean', \n",
    "                                     ])\n",
    "        \n",
    "    for user in users:\n",
    "        print (\"User \", user)\n",
    "        with open(BASE_DIR + \"/\" +  'all_reward_fns.csv', newline='') as csvf:\n",
    "            csvreader = csv.reader(csvf, delimiter=',', quotechar='\"')\n",
    "            for idx, row in enumerate(csvreader):\n",
    "                if idx == 0:\n",
    "                    continue\n",
    "                user_id = row[0]  \n",
    "                selected_agent = row[7]\n",
    "                if user_id == str(user):\n",
    "                    reward_fn = list(eval(row[2]).values())\n",
    "                    reward_fn_idx = cumulative_df.loc[cumulative_df['Reward Function'] == str(reward_fn)]\n",
    "                    if not reward_fn_idx.empty: \n",
    "                        overfitting_csv_writer.writerow([user_id,\n",
    "                                                        reward_fn,\n",
    "                                                        'TRUE', \n",
    "                                                        selected_agent, \n",
    "                                                        int(reward_fn_idx[\"DDQN_rank\"].values[0]),\n",
    "                                                        int(reward_fn_idx[\"DDQN\"].values[0]),\n",
    "                                                        int(reward_fn_idx[\"PPO_rank\"].values[0]),\n",
    "                                                        int(reward_fn_idx[\"PPO\"].values[0]),\n",
    "                                                        int(reward_fn_idx[\"A2C_rank\"].values[0]),\n",
    "                                                        int(reward_fn_idx[\"A2C\"].values[0]),\n",
    "                                                        int(reward_fn_idx[\"QLearn_rank\"].values[0]),\n",
    "                                                        int(reward_fn_idx[\"QLearn\"].values[0]),\n",
    "                                                        ])\n",
    "                    else:\n",
    "                        overfitting_csv_writer.writerow([user_id, \n",
    "                                                         reward_fn,\n",
    "                                                         'FALSE'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}